{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Planet Analytics API Tutorial\n",
    "\n",
    "# Summary Statistics: Ships\n",
    "\n",
    "## Overview\n",
    "    \n",
    "1. [Introduction](#1.-Introduction)\n",
    "2. [Post a stats job request](#2.-Post-a-stats-job-request)\n",
    "3. [Poll the stats job endpoint](#3.-Poll-the-stats-job-endpoint)\n",
    "4. [Get the job report results](#4.-Get-the-job-report-results)\n",
    "5. [Restructure the results into a pandas dataframe](#5.-Restructure-the-results-into-a-pandas-dataframe)\n",
    "6. [Visualize the time series](#6.-Visualize-the-time-series)\n",
    "7. [Normalize and clean the report data](#7.-Normalize-and-clean-the-report-data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This notebook demonstrates how to request road summary statistics for a subscription using the Anaytics Feeds Stats API and visualize them as time series, enabling further analyses including patterns of life, development trends and anomaly detection. Access to an object detection subscription (ships or planes) is required to run the notebook. \n",
    "\n",
    "The workflow involves:\n",
    "- Posting a stats job request\n",
    "- Polling the job stats endpoint\n",
    "- Getting the job report results\n",
    "- Restructuring the results into a pandas dataframe\n",
    "- Normalizing and cleaning the report data\n",
    "- Visualizing the time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import and install external dependencies\n",
    "This notebook requires hvplot, which may not be available in the main notebook docker image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hvplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import pprint\n",
    "import time\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "from bokeh.models.formatters import DatetimeTickFormatter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Post a stats job request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Check API Connection\n",
    "_**Note:** If you do not have access to the Analytics Feeds API, you may not be able to run through these examples. Contact [Sales](go.planet.com/getintouch) to learn more._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANALYTICS_BASE_URL = 'https://api.planet.com/analytics/'\n",
    "# change this line if your API key is not set as an env var\n",
    "API_KEY = os.environ['PL_API_KEY']\n",
    "# alternatively, you can just set your API key directly as a string variable:\n",
    "# API_KEY = \"YOUR_PLANET_API_KEY_HERE\"\n",
    "# set up a reusable session with required headers\n",
    "session = requests.Session()\n",
    "session.headers.update({'content-type':'application/json','Authorization': 'api-key ' + API_KEY})\n",
    "# make a request to the analytics api\n",
    "resp = session.get(ANALYTICS_BASE_URL)\n",
    "if resp.ok:\n",
    "    print(\"Yay, you are able to connect to the Planet Analytics API!\")\n",
    "else:\n",
    "    print(\"Something is wrong:\", resp.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Select your subscription\n",
    "The analytics stats API enables you to create summary stats reports for your analytics subscriptions. You will need the id of a subscription of interest in order to make a stats request. This notebook uses the Singapore Strait ships subscription by default (f3aef23c-a540-458e-a3b5-979b7920d2ea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you have access to the subscription\n",
    "subscription_id = 'f3aef23c-a540-458e-a3b5-979b7920d2ea'\n",
    "resp = session.get(f\"{ANALYTICS_BASE_URL}subscriptions/{subscription_id}\")\n",
    "if not resp.ok:\n",
    "    raise Exception('Bad response:', resp.content)\n",
    "else:\n",
    "    print(\"Subscription info:\")\n",
    "    print(resp.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Post a stats report job request to the AF API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_body = {\n",
    "    \"title\": \"Stats Demo - Ships\",\n",
    "    \"subscriptionID\": subscription_id,\n",
    "    \"interval\": \"day\",  # most object detection feeds generate results on a daily cadence\n",
    "#     \"collection\": collection,  # remove this line if you want to use the default subscription geometry\n",
    "#     \"startTime\": start_time,  # remove this line if you want to use the default subscription startTime\n",
    "#     \"endTime\": end_time  # remove this line if you want to use the default subscription endTime\n",
    "}\n",
    "\n",
    "stats_post_url = ANALYTICS_BASE_URL + 'stats'\n",
    "\n",
    "job_post_resp = session.post(\n",
    "    stats_post_url, \n",
    "    data=json.dumps(request_body)\n",
    ")\n",
    "\n",
    "pprint.pprint(job_post_resp.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Poll the stats job endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_link = job_post_resp.json()['links'][0]['href']\n",
    "status = \"pending\"\n",
    "while status != \"completed\":\n",
    "    report_status_resp = session.get(\n",
    "        job_link,\n",
    "    )\n",
    "    status = report_status_resp.json()['status']\n",
    "    print(status)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    \n",
    "pprint.pprint(report_status_resp.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get the job report results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_results_link = report_status_resp.json()['links'][-1]['href']\n",
    "report_results_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_resp = session.get(\n",
    "    report_results_link,\n",
    ")\n",
    "print(results_resp.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Restructure the results into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restructure_results(results_json):\n",
    "    cols = results_json['cols']\n",
    "    rows = results_json['rows']\n",
    "    \n",
    "    records = []\n",
    "    for r in rows:\n",
    "        rec = defaultdict()\n",
    "        for i, cell in enumerate(r):\n",
    "            rec[cols[i]['label']] = cell\n",
    "        records.append(rec)\n",
    "        \n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    df['Start Time'] = pd.to_datetime(df['Start Time'])\n",
    "    df = df.set_index('Start Time')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = restructure_results(results_resp.json())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('bokeh')\n",
    "formatter = DatetimeTickFormatter(months='%b %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total Object Count'].hvplot().options(xformatter=formatter, width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Normalize and clean the report data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph above is likely very noisy due to clouds, haze, and a variation in the amount of imagery per day. The steps below normalize the object count by the estimated area of usable imagery that the model observed. Planet currently provides two versions of an unusable data mask (UDM) for most scenes. Udm (version 1) is less accurate but is available for every scene. Udm2 is more accurate but is sometimes unavailable. The steps below use udm2 to estimate the percentage of pixels that are usable (i.e. not cloudy), and the original udm to estimate the total imaged area per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('precision', 15)\n",
    "\n",
    "# Get the total area of the subscription or submitted feature (sq m)\n",
    "submitted_area = df['Submitted Area'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Remove time points that contain < 50% clear imagery\n",
    "On cloudy days results are less likely to be accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clear Percentage'] = df['Clear Area (udm2_band_1)'] / df['Total Area (udm2)']\n",
    "df = df[df['Clear Percentage'] > 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Remove time points where imagery coverage is < 50%\n",
    "If only a small section of the AOI contains imagery, inferring the object count for the whole AOI is less accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Imagery Coverage'] = df['Total Area (udm2)'] / submitted_area\n",
    "df = df[df['Imagery Coverage'] > 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Estimate usable area per time point\n",
    "Models can often detect objects through light haze and sometimes through heavy haze, so we use that rough information to create an estimated \"usable percentage\" metric. You can adjust the parameters if you know the model your using performs better or worse in haze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count 100% of light haze area as usable\n",
    "light_haze_weight = 1.0\n",
    "# Count 50% of heavy haze area as usable\n",
    "heavy_haze_weight = 0.5\n",
    "\n",
    "# Create a column that estimates the percentage of imagery where the model is expected to perform.\n",
    "df['Usable Percentage'] = (df['Clear Area (udm2_band_1)'] + (df['Light Haze Area (udm2_band_4)'] * light_haze_weight) + (df['Heavy Haze Area (udm2_band_5)'] * heavy_haze_weight)) / df['Total Area (udm2)']\n",
    "# Create a column that estimates usable area. In some cases udm2 assets are missing, so the most accurate measurement of total area that the model has seen comes from the udm Total Area column.\n",
    "df['Usable Area'] = df['Usable Percentage'] * df['Total Area (udm)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Normalize the object count\n",
    "Create a normalized object count by getting the object count per usable square meter and multiplying by the total aoi size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Normalized Count'] = round((df['Total Object Count'] / df['Usable Area']) * submitted_area).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Vizualize the normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_count = df['Normalized Count'].max()\n",
    "df['Normalized Count'].hvplot().options(xformatter=formatter, width=800, ylim=(0,max_count + (max_count * .1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're using the demo Singapore Strait ships subscription the graph above should appear roughly flat, meaning that no major changes in counts of ships were found in the subscription. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
