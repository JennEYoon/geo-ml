{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Planet Analytics API Tutorial\n",
    "\n",
    "<h1 style=\"margin-top:10px;\">Case Study: Flood and Displacement Mapping in Syria</h1>\n",
    "</div>\n",
    "<div class=\"content-block\">\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. [Setup](#1.-Setup)\n",
    "\n",
    "2. [Case Study](#2.-Case-Study)\n",
    "\n",
    "3. [Mapping our Area of Interest](#3.-Mapping-AOI) \n",
    "\n",
    "4. [Working with Collections](#4.-Working-with-Collections)\n",
    "    \n",
    "5. [Parsing Results](#5.-Parse-Results-Links)\n",
    "    \n",
    "6. [Segmentation Results](#6.-Segmentation-Results)\n",
    "    \n",
    "7. [Quantifying Change](#7.-Quantifying-Change)\n",
    "    \n",
    "8. [Line Charts](#8.-Line-Charts)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "To run through this notebook, you will need access to the following:\n",
    "- A Planet account and Planet API Key\n",
    "- Access to the Analytics API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# if your Planet API Key is not set as an environment variable, you can paste it below\n",
    "if os.environ.get('PL_API_KEY', ''):\n",
    "    API_KEY = os.environ.get('PL_API_KEY', '')\n",
    "else:\n",
    "    API_KEY = 'PASTE YOUR API KEY HERE'\n",
    "\n",
    "    # construct auth tuple for use in the requests library\n",
    "BASIC_AUTH = (API_KEY, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the base url for the Planet Analytic Feeds product**\n",
    "\n",
    "See the [Analytics API Docs](https://developers.planet.com/docs/analytics/) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://api.planet.com/analytics/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check API Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "feed_list_url = BASE_URL + 'feeds'\n",
    "resp = requests.get(feed_list_url, auth=BASIC_AUTH, params={'limit': 1})\n",
    "if resp.status_code == 200:\n",
    "    print('Yay, you can access the Analytics API')\n",
    "else:\n",
    "    print('Something is wrong:', resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Case Study\n",
    "\n",
    "Near the end of 2018, Syria experienced severe rainfall and flooding across much of the Northern latitudes of the country. This flooding had devastating impacts to several Internally Displaced Persons (IDP) camps  across the region, as [reported](https://www.savethechildren.net/news/northern-syria-flooding-thousands-children-risk-further-displacement)  in [several](https://reliefweb.int/report/syrian-arab-republic/record-rainfall-devastates-idp-camps-northern-syria) small media [outlets](https://arab24.com/portal/index.php/arab24-stories/syria/item/12613-2018-12-07-15-17-41). \n",
    "\n",
    "Today, we are interested using Planet's Analytic Feeds to explore both the development of an IDP Camp south of Al Hasakah, and the impacts of the flooding of this area in subsequent years. We will use the following buildings and roads suscription IDs to collect our data.\n",
    "\n",
    "**Note:** If you do not have access to these subscriptions, please [get in touch](https://www.planet.com/contact-sales/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_sub_id = '76d06ec1-8507-4035-97cd-b3ea87b5b699'\n",
    "roads_sub_id = '6696da5c-88b8-49c2-a423-c936c0f386a5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new url to request the subscriptions endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscriptions_url = BASE_URL + 'subscriptions/'\n",
    "\n",
    "syria_buildings = requests.get(subscriptions_url + buildings_sub_id, auth=BASIC_AUTH).json()\n",
    "syria_roads = requests.get(subscriptions_url + roads_sub_id, auth=BASIC_AUTH) .json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `pprint` library to structure our json responses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(syria_buildings)\n",
    "print('')\n",
    "pprint(syria_roads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mapping AOI\n",
    "\n",
    "**Inspecting subscription details**\n",
    "\n",
    "Subscriptions have a spatial area of interest described by a geojson geometry. We can visualize the area of interest for a subscription on a map. First, let's just confirm that the geometries are the same for both roads and buildings subscriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if syria_buildings['geometry'] == syria_roads['geometry']:\n",
    "    print('The geometries are the same!')\n",
    "    aoi = syria_buildings['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, GeoJSON, LocalTileLayer, LayersControl, SplitMapControl, WidgetControl\n",
    "from ipywidgets import SelectionSlider, VBox\n",
    "from numpy import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's center the map at the centroid of our geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lat = min(coord[1] for coord in aoi['coordinates'][0])\n",
    "max_lat = max(coord[1] for coord in aoi['coordinates'][0])\n",
    "min_lon = min(coord[0] for coord in aoi['coordinates'][0])\n",
    "max_lon = max(coord[0] for coord in aoi['coordinates'][0])\n",
    "\n",
    "map_center = (mean([min_lat, max_lat]), mean([min_lon, max_lon]))\n",
    "print(map_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a map, and draw the subscription geometry\n",
    "m = Map(center=map_center, zoom=12)\n",
    "\n",
    "# convert to leaflet GeoJSON object\n",
    "map_AOI = GeoJSON(\n",
    "    data = aoi, \n",
    "    style = {'color': 'blue', 'opacity':0.5, 'weight':1.5, 'dashArray':'5', 'fillOpacity':0.1}\n",
    ")\n",
    "\n",
    "m.add_layer(map_AOI)\n",
    "    \n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a sense of our study AOI, let's inspect Planet's source imagery and Analytic Feeds results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Working with Collections\n",
    "\n",
    "As should now be familiar, Planet Analytic Feeds results can be accessed via the `collections` endpoint. We can find the results for our particular subscriptions in the `links` property from the results of our last `subscriptions` requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_collection_endpoint = [link['href'] for link in syria_buildings['links'] if link['rel'] == 'results'][0]\n",
    "roads_collection_endpoint = [link['href'] for link in syria_roads['links'] if link['rel'] == 'results'][0]\n",
    "\n",
    "print('Buildings Collection URL: {}'.format(buildings_collection_endpoint))\n",
    "print('Roads Collection URL: {}'.format(roads_collection_endpoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Request the Collections API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_results = requests.get(buildings_collection_endpoint, auth=BASIC_AUTH).json()\n",
    "roads_results = requests.get(roads_collection_endpoint, auth=BASIC_AUTH).json()\n",
    "\n",
    "print('We got {} buildings results!'.format(len(building_results['features'])))\n",
    "print('We got {} roads results!'.format(len(roads_results['features'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Parse Results Links\n",
    "\n",
    "Our results come back nicely wrapped as GeoJSON FeatureCollection. We can easily put them into a Pandas Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parse Buildings Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert links and properties to dataframe\n",
    "buildings = pd.json_normalize(building_results['features']).loc[:, ['links', 'properties.observed']]\n",
    "\n",
    "# extract links \n",
    "buildings['source_tiles'] = buildings['links'].map(lambda links: [link['href'] for link in links if link['rel'] == 'source-tiles'][0])\n",
    "buildings['buildings_tiles'] = buildings['links'].map(lambda links: [link['href'] for link in links if link['rel'] == 'target-tiles'][0]).map(lambda x: x + '&exp=bincat:0|39039e')\n",
    "buildings['b_source_quad'] = buildings['links'].map(lambda links: [link['href'] for link in links if link['rel'] == 'source-quad'][0])\n",
    "buildings['buildings_quad'] = buildings['links'].map(lambda links: [link['href'] for link in links if link['rel'] == 'target-quad'][0])\n",
    "\n",
    "# drop links column\n",
    "buildings.drop(labels=['links'], axis=1, inplace=True)\n",
    "\n",
    "# change column names\n",
    "buildings.rename(columns = {'properties.observed': 'date'}, inplace=True)\n",
    "buildings['date'] = buildings['date'].map(lambda x: x.split('T')[0])\n",
    "buildings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do the same as above for our Roads Segmentation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads = pd.json_normalize(roads_results['features']).loc[:, ['links', 'properties.observed']]\n",
    "\n",
    "# extract links \n",
    "roads['source_tiles'] = roads['links'].map(lambda links: [link['href'] for link in links if link['rel'] == 'source-tiles'][0])\n",
    "roads['roads_tiles'] = roads['links'].map(lambda links: [link['href'] for link in links if link['rel'] == 'target-tiles'][0]).map(lambda x: x + '&exp=bincat:0|d65a45')\n",
    "roads['r_source_quad'] = roads['links'].map(lambda links: [link['href'] for link in links if link['rel'] == 'source-quad'][0])\n",
    "roads['roads_quad'] = roads['links'].map(lambda links: [link['href'] for link in links if link['rel'] == 'target-quad'][0])\n",
    "\n",
    "# drop links column\n",
    "roads.drop(labels=['links'], axis=1, inplace=True)\n",
    "\n",
    "# change column names\n",
    "roads.rename(columns = {'properties.observed': 'date'}, inplace=True)\n",
    "roads['date'] = roads['date'].map(lambda x: x.split('T')[0])\n",
    "\n",
    "roads.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's combine our roads and buildings results into a single feature dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnb = buildings.merge(roads, on=['date', 'source_tiles'])\n",
    "rnb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's create separate dataframes for tiles and quads. We'll use the tiles to visualize our AOI in a few web maps, and the quads for a later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = rnb.loc[:, ['date', 'source_tiles', 'buildings_tiles', 'roads_tiles']].drop_duplicates()\n",
    "\n",
    "# Sort dataframe by time\n",
    "tiles = tiles.sort_values(by='date').reset_index(drop=True)\n",
    "tiles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quads dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quads = rnb.loc[:, ['date', 'r_source_quad', 'b_source_quad', 'roads_quad', 'buildings_quad']]\n",
    "\n",
    "# Sort dataframe by time\n",
    "quads.sort_values(by='date', inplace=True)\n",
    "quads.reset_index(drop=True, inplace=True)\n",
    "quads.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Segmentation Results\n",
    "\n",
    "First, let's take a look at our results for the first date in our subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = tiles['date'].unique()\n",
    "print('First date: {}'.format(times[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Map(center=map_center, zoom=13)\n",
    "\n",
    "building_mask = LocalTileLayer(\n",
    "    path=tiles.loc[0, 'buildings_tiles'], \n",
    "    name=f\"Buildings: {tiles.loc[0, 'date']}\"\n",
    ")\n",
    "\n",
    "road_mask = LocalTileLayer(\n",
    "    path=tiles.loc[0, 'roads_tiles'], \n",
    "    name=f\"Roads: {tiles.loc[0, 'date']}\"\n",
    ")\n",
    "\n",
    "basemap = LocalTileLayer(\n",
    "    path=tiles.loc[0, 'source_tiles'], \n",
    "    name='Source image'\n",
    ")\n",
    "\n",
    "m.add_layer(basemap)\n",
    "m.add_layer(road_mask)\n",
    "m.add_layer(building_mask)\n",
    "\n",
    "m.add_control(LayersControl(position='topright'))\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Map**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `SplitMapControl`, we can easily swipe between pre- and post-flood imagery and building overlays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Map(center=map_center, zoom=13)\n",
    "\n",
    "# first time-point\n",
    "building_mask_1 = LocalTileLayer(\n",
    "    path=tiles.loc[16, 'buildings_tiles'], name=f\"Buildings: {tiles.loc[16, 'date']}\")\n",
    "\n",
    "road_mask_1 = LocalTileLayer(\n",
    "    path=tiles.loc[16, 'roads_tiles'], name=f\"Roads: {tiles.loc[16, 'date']}\")\n",
    "\n",
    "basemap_1 = LocalTileLayer(\n",
    "    path=tiles.loc[16, 'source_tiles'], name=tiles.loc[17, 'date'])\n",
    "\n",
    "\n",
    "# add second time series\n",
    "building_mask_2 = LocalTileLayer(\n",
    "    path=tiles.loc[18, 'buildings_tiles'], name=f\"Buildings: {tiles.loc[18, 'date']}\")\n",
    "\n",
    "road_mask_2 = LocalTileLayer(\n",
    "    path=tiles.loc[18, 'roads_tiles'], name=f\"Roads: {tiles.loc[18, 'date']}\")\n",
    "\n",
    "basemap_2 = LocalTileLayer(\n",
    "    path=tiles.loc[18, 'source_tiles'], name=tiles.loc[18, 'date'])\n",
    "\n",
    "# add layers\n",
    "m.add_layer(road_mask_1)\n",
    "m.add_layer(building_mask_1)\n",
    "\n",
    "m.add_layer(road_mask_2)\n",
    "m.add_layer(building_mask_2)\n",
    "\n",
    "splitter = SplitMapControl(left_layer=[building_mask_1, road_mask_1, basemap_1], \n",
    "                           right_layer=[building_mask_2, road_mask_2, basemap_2])\n",
    "\n",
    "# add controls\n",
    "m.add_control(LayersControl(position='topright'))\n",
    "m.add_control(splitter)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date Slider**\n",
    "\n",
    "We can toggle through our time points with greater granularity using a Date Slider widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Map(center=map_center, zoom=13)\n",
    "\n",
    "date_slider = SelectionSlider(description='Time:', options=times)\n",
    "\n",
    "current_date = '2017-07-01'\n",
    "\n",
    "# create and add initial layers\n",
    "source_layer=LocalTileLayer(path=tiles.loc[tiles['date'] == current_date, 'source_tiles'].iloc[0])\n",
    "roads_layer=LocalTileLayer(path=tiles.loc[tiles['date'] == current_date, 'roads_tiles'].iloc[0])\n",
    "buildings_layer=LocalTileLayer(path=tiles.loc[tiles['date'] == current_date, 'buildings_tiles'].iloc[0])\n",
    "\n",
    "m.add_layer(source_layer)\n",
    "m.add_layer(roads_layer)\n",
    "m.add_layer(buildings_layer)\n",
    "\n",
    "def get_source_url(change):\n",
    "    global tiles\n",
    "    source_url = tiles.loc[tiles['date'] == change, 'source_tiles'].iloc[0]\n",
    "    return source_url\n",
    "\n",
    "def get_road_url(change):\n",
    "    global tiles\n",
    "    roads_url = tiles.loc[tiles['date'] == change, 'roads_tiles'].iloc[0]\n",
    "    return roads_url\n",
    "\n",
    "def get_building_url(change):\n",
    "    global tiles\n",
    "    buildings_url = tiles.loc[tiles['date'] == change, 'buildings_tiles'].iloc[0]\n",
    "    return buildings_url\n",
    "\n",
    "def display_tiles(change):\n",
    "    global source_layer\n",
    "    global roads_layer\n",
    "    global buildings_layer\n",
    "    global current_date\n",
    "    \n",
    "    if current_date != date_slider.value:\n",
    "        current_date = date_slider.value\n",
    "    \n",
    "   # update source imagery\n",
    "    source_layer = LocalTileLayer(path=get_source_url(current_date))\n",
    "    \n",
    "    # update roads mask\n",
    "    roads_layer= LocalTileLayer(path=get_road_url(current_date))\n",
    "    \n",
    "    # update buildings mask\n",
    "    buildings_layer = LocalTileLayer(path=get_building_url(current_date))\n",
    "    \n",
    "    # add new layers\n",
    "    m.add_layer(source_layer)\n",
    "    m.add_layer(roads_layer)\n",
    "    m.add_layer(buildings_layer)\n",
    "\n",
    "# link \n",
    "date_slider.observe(display_tiles, 'value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display Map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VBox([date_slider, m])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Quantifying Change\n",
    "_Calculating Buildings and Roads Pixels_\n",
    "\n",
    "The above visualizations allow for a great qualitative analysis of our AOI, with the roads and buildings masks drawing our attention to the changing features over time. Now, let's use some raster tools to quantitatively measure the changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify New AOI**\n",
    "\n",
    "We'll use a condensed polygon centered around the region of development and flooding we observed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_aoi = {'type': 'Polygon',\n",
    "           'coordinates': [[[40.746897, 36.270941],\n",
    "                            [40.746897, 36.294431],\n",
    "                            [40.790485, 36.294431],\n",
    "                            [40.790485, 36.270941],\n",
    "                            [40.746897, 36.270941]]]\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Coordinate Reference Systems\n",
    "\n",
    "Leaflet Maps and Planet's Tile Services/ Quads use a different coordinate reference system. So, we'll need to transform the above geometry to properly align our AOI and imagery.\n",
    "\n",
    "   - Leaflet CRS: `EPSG 4326`\n",
    "   - Planet CRS: `EPSG 3857`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "from rasterio.warp import transform_geom\n",
    "from shapely.geometry import shape\n",
    "from numpy import count_nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform AOI\n",
    "transformed_aoi = rio.warp.transform_geom(src_crs='EPSG:4326', dst_crs='EPSG:3857', geom=new_aoi, precision=6)\n",
    "\n",
    "pprint(transformed_aoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_download_url(quad_url, auth):\n",
    "    \"\"\"\n",
    "    utility function to get the target-quad download url\n",
    "    \n",
    "    This enables reading Planet Quads using Rasterio without local download!\n",
    "    \"\"\" \n",
    "    resp = requests.get(quad_url, \n",
    "                        auth=auth,\n",
    "                        allow_redirects=False)\n",
    "    \n",
    "    assert resp.status_code == 302\n",
    "    \n",
    "    return resp.headers['Location']\n",
    "\n",
    "def get_geometry_bounds(aoi):\n",
    "    \"\"\"\n",
    "    Converts GeoJSON-like feature to Shapely geometry object.\n",
    "    \n",
    "    Returns bounds of object\n",
    "    \"\"\"\n",
    "    geo_to_shape = shape(aoi)\n",
    "    \n",
    "    xmin, ymin, xmax, ymax = geo_to_shape.bounds\n",
    "    \n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "def read_window(dataset, xmin, ymin, xmax, ymax):\n",
    "    \"\"\"\n",
    "    Performs a windowed read of a GeoTiff using the geometry bounds of an AOI\n",
    "    \n",
    "    Returns the window as a 1 dimensional numpy array.\n",
    "    \"\"\"    \n",
    "    windarray = dataset.read(\n",
    "                    indexes=1, # only reads the binary segmentation mask band\n",
    "                    window=rio.windows.from_bounds(\n",
    "                        xmin, ymin, xmax, ymax,\n",
    "                        transform=dataset.transform))\n",
    "\n",
    "    return windarray\n",
    "\n",
    "def get_pixel_counts(windarray):\n",
    "    \"\"\"\n",
    "    Calculates the sum of non-zero (e.g. roads, buildings) pixels in an array\n",
    "    \"\"\"\n",
    "    return count_nonzero(windarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a proof of concept, let's read in one Quad to get a sense of it's shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_quad_url = get_download_url(quads.loc[0, 'roads_quad'], auth=BASIC_AUTH)\n",
    "\n",
    "ex_quad =  rio.open(first_quad_url)\n",
    "print(ex_quad.read().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the [docs](https://developers.planet.com/docs/analytics/apiresponse/#collections-for-raster-results), raster results are in the form of a two band GEOTIFF. The first band contains the binary mask data (this is what we are interested in!). The second band represents valid or invalid source imagery pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's read all of our Quads and store their pixel counts in a `pixel_counts` dictionary.\n",
    "\n",
    "Our AOI intersects two source quads, and the segmentation results overlay those quads for each of our time points. So, we'll be reading data from four quads for every point in our time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_counts = {time: {'building_px': 0, 'road_px':0, 'total_px':0} for time in times}\n",
    "\n",
    "# Get bounds of our AOI\n",
    "xmin, ymin, xmax, ymax = get_geometry_bounds(transformed_aoi)\n",
    "\n",
    "# this will take a little while...\n",
    "for time in tqdm(times):\n",
    "    building_pixels = 0\n",
    "    roads_pixels = 0\n",
    "\n",
    "    for idx, row in quads.loc[quads['date'] == time, :].iterrows():\n",
    "        \n",
    "        # get quad items urls\n",
    "        buildings_quad = row['buildings_quad']\n",
    "        roads_quad = row['roads_quad']\n",
    "        \n",
    "        # get quad download urls\n",
    "        buildings_url = get_download_url(buildings_quad, auth=BASIC_AUTH)\n",
    "        roads_url = get_download_url(roads_quad, auth=BASIC_AUTH)\n",
    "        \n",
    "        # read quad segmentation mask band\n",
    "        buildings_data = rio.open(buildings_url)\n",
    "        roads_data = rio.open(roads_url)\n",
    "        \n",
    "        buildings_window = read_window(buildings_data, xmin, ymin, xmax, ymax)\n",
    "        roads_window = read_window(roads_data, xmin, ymin, xmax, ymax)\n",
    "        \n",
    "        # count buildings and road pixels\n",
    "        building_count = count_nonzero(buildings_window)\n",
    "        roads_count = count_nonzero(roads_window)\n",
    "        \n",
    "        # store in dictionary under time key\n",
    "        building_pixels += building_count\n",
    "        roads_pixels += roads_count\n",
    "    \n",
    "    pixel_counts[time]['building_px'] = building_pixels\n",
    "    pixel_counts[time]['road_px'] = roads_pixels\n",
    "    pixel_counts[time]['total_px'] = building_pixels + roads_pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting `pixel_counts` to a dataframe will make plotting a breeze!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_counts = pd.DataFrame(data=pixel_counts.values(), index=pixel_counts.keys())\n",
    "pixel_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Line Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot building pixels over time\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Building Pixels over Time', fontdict={'size':18})\n",
    "\n",
    "plt.vlines(x=[idx for idx, time in enumerate(times) if time == '2017-09-01'][0], \n",
    "           ymin=pixel_counts['building_px'].min(), \n",
    "           ymax=pixel_counts['building_px'].max(), \n",
    "           colors='r', linestyles='dashed', alpha=0.5)\n",
    "\n",
    "plt.vlines(x=[idx for idx, time in enumerate(times) if time == '2018-11-01'][0], \n",
    "           ymin=pixel_counts['building_px'].min(), \n",
    "           ymax=pixel_counts['building_px'].max(), \n",
    "           colors='r', linestyles='dashed', alpha=0.5)\n",
    "\n",
    "pixel_counts['building_px'].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above plot for building pixels, we can broadly quantify the change in buildings in our AOI over the time of our subscription. As indicated on the plot, we see a sudden spike in buildings from September to Novemeber 2017, as the IDP camp settles on the same penninsula. Then - despite some noise in the pixel counts - we can detect the drop in buildings at the end of 2018 as severe flooding alters the camp and surrounding landscape.\n",
    "\n",
    "Next, let's look at the pattern for roads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Road Pixels over Time', fontdict={'size':18})\n",
    "\n",
    "plt.vlines(x=[idx for idx, time in enumerate(times) if time == '2017-09-01'][0], \n",
    "           ymin=pixel_counts['road_px'].min(), \n",
    "           ymax=pixel_counts['road_px'].max(), \n",
    "           colors='r', linestyles='dashed', alpha=0.5)\n",
    "\n",
    "plt.vlines(x=[idx for idx, time in enumerate(times) if time == '2018-11-01'][0], \n",
    "           ymin=pixel_counts['road_px'].min(), \n",
    "           ymax=pixel_counts['road_px'].max(), \n",
    "           colors='r', linestyles='dashed', alpha=0.5)\n",
    "\n",
    "pixel_counts['road_px'].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our plot of road pixels over time shows a different trend. While also prone to some month-to-month noise, we can see early that the high number of road pixels is consistent with the construction of the roads scaffolding as early as August, 2017. After the flooding, we see a slight change in road pixels, too. However, this coincides with new road construction in an adjacent camp in our AOI. \n",
    "\n",
    "Finally, we can visualize the count of combined roads and buildings pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.title('Roads & Buildings Pixels over Time', fontdict={'size':18})\n",
    "\n",
    "plt.vlines(x=[idx for idx, time in enumerate(times) if time == '2017-09-01'][0], \n",
    "           ymin=pixel_counts['total_px'].min(), \n",
    "           ymax=pixel_counts['total_px'].max(), \n",
    "           colors='r', linestyles='dashed', alpha=0.5)\n",
    "\n",
    "plt.vlines(x=[idx for idx, time in enumerate(times) if time == '2018-11-01'][0], \n",
    "           ymin=pixel_counts['total_px'].min(), \n",
    "           ymax=pixel_counts['total_px'].max(), \n",
    "           colors='r', linestyles='dashed', alpha=0.5)\n",
    "\n",
    "pixel_counts['total_px'].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the line chart for combined roads and buildings pixels, we can observe the overall trend in the development and change to this IDP camp. With this simple method of quantifying change, we can readily pick out specific time points with broader changes from a large time range. \n",
    "\n",
    "With Planet Analytic Feeds, change can be observed in near real-time, enabling enhanced monitoring capabilities, insights at the speed of change, and data-driven decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
